const { GoogleGenerativeAI } = require('@google/generative-ai');
const yaml = require('js-yaml');

// Initialize Gemini AI with test case validation API key
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY_TEST_CASE_VALIDATION);

/**
 * Validates test cases generated by AI for a problem
 * @param {Object} problemData - The problem data including statement, constraints, and test cases
 * @returns {Object} Validation report with detailed analysis
 */
const validateTestCases = async (problemData) => {
  const maxRetries = 3;
  let attempt = 0;
  
  while (attempt < maxRetries) {
    try {
      const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });

    // Construct the validation prompt
    const prompt = `You are an expert competitive programming judge. Analyze if the test cases are CORRECT for this problem.

PROBLEM:
Title: ${problemData.title}
Description: ${problemData.description}

Constraints:
${problemData.constraints.map((c, i) => `${i + 1}. ${c}`).join('\n')}

Time Complexity: ${problemData.timeComplexity}
Space Complexity: ${problemData.spaceComplexity}

Examples:
${problemData.examples.map((ex, i) => `Example ${i + 1}:
Input: ${ex.input}
Output: ${ex.output}
Explanation: ${ex.explanation}`).join('\n\n')}

TEST CASES TO VALIDATE:
${problemData.testCases.map((tc, i) => `Test Case ${i + 1}:
Input: ${tc.input}
Output: ${tc.output}`).join('\n\n')}

YOUR TASK:
For EACH test case, check if the output is CORRECT for the given input based on the problem statement.
Provide a brief explanation for each test case.

CRITICAL: Return response in PURE YAML format (no markdown, no code blocks).

Required structure:
---
isValid: true
overallScore: 100
summary: "All test cases have correct outputs"
testCaseResults:
  - testCaseNumber: 1
    isValid: true
    explanation: "Output correctly follows the algorithm"
    issues: []
  - testCaseNumber: 2
    isValid: true
    explanation: "Edge case handled properly"
    issues: []
  - testCaseNumber: 3
    isValid: false
    explanation: "Output doesn't match expected result"
    issues:
      - "Expected output is X but got Y because of reason Z"

RULES:
- isValid: true if test case output is correct, false otherwise
- overallScore: 100 if all correct, 0 if all wrong, percentage for partial
- For EACH test case provide an explanation field (brief reason why valid/invalid)
- For each test case, mark isValid true/false based ONLY on output correctness
- Put issues ONLY if output is wrong, explain what's wrong in detail
- Keep all text on single lines
- NO suggestions, NO recommendations, NO coverage comments
- Start with "isValid:" - NO markdown blocks`;

      console.log('\n=== VALIDATION PROMPT ===');
      console.log(prompt);
      console.log('=== END VALIDATION PROMPT ===\n');

      const result = await model.generateContent(prompt);
      const response = await result.response;
      const text = response.text();    console.log('Raw Validation Response (first 300 chars):', text.substring(0, 300));

    // Clean the response more aggressively
    let cleanedText = text.trim();
    
    // Remove YAML document separator if present
    if (cleanedText.startsWith('---')) {
      cleanedText = cleanedText.substring(3).trim();
    }
    
    // Remove all markdown code blocks
    cleanedText = cleanedText.replace(/```yaml\n?/g, '');
    cleanedText = cleanedText.replace(/```\n?/g, '');
    
    // Remove YAML multi-line string indicators that cause parsing issues
    cleanedText = cleanedText.replace(/\|\s*$/gm, ''); // Remove trailing pipes
    cleanedText = cleanedText.replace(/>\s*$/gm, ''); // Remove trailing >
    
    // Fix common problematic characters
    cleanedText = cleanedText.replace(/\|S\|/g, 'S'); // Remove absolute value notation
    cleanedText = cleanedText.replace(/\|([^|:"\n]+)\|/g, '$1'); // Remove other pipes (but not in strings)
    
    cleanedText = cleanedText.trim();

    console.log('Cleaned YAML (first 500 chars):', cleanedText.substring(0, 500));

    // Parse YAML response
    let validationReport;
    try {
      validationReport = yaml.load(cleanedText, { json: true }); // Use JSON mode for safer parsing
      console.log('Successfully parsed validation report');
    } catch (parseError) {
      console.error('YAML Parse Error:', parseError.message);
      console.error('Problematic YAML (first 1000 chars):', cleanedText.substring(0, 1000));
      throw new Error(`Invalid YAML response from validation AI: ${parseError.message}`);
    }

    // Validate required fields
    if (typeof validationReport.isValid !== 'boolean' || 
        typeof validationReport.overallScore !== 'number') {
      throw new Error('Validation report missing required fields');
    }

    // Ensure arrays exist
    validationReport.testCaseResults = Array.isArray(validationReport.testCaseResults) 
      ? validationReport.testCaseResults : [];

    // Add validation timestamp
    validationReport.validatedAt = new Date();

    return validationReport;

    } catch (error) {
      attempt++;
      
      // Check if it's a rate limit error
      if (error.message && error.message.includes('quota') && attempt < maxRetries) {
        const waitTime = Math.pow(2, attempt) * 5000; // Exponential backoff: 5s, 10s, 20s
        console.log(`Validation rate limit hit. Waiting ${waitTime / 1000}s before retry ${attempt + 1}/${maxRetries}...`);
        await new Promise(resolve => setTimeout(resolve, waitTime));
        continue;
      }
      
      // If max retries reached or other error, throw
      if (attempt >= maxRetries) {
        console.error('Error validating test cases (max retries reached):', error);
        throw new Error(`Failed to validate test cases after ${maxRetries} attempts: ${error.message}`);
      }
      
      // For non-rate-limit errors, throw immediately
      console.error('Error validating test cases with Gemini AI:', error);
      throw new Error(`Failed to validate test cases: ${error.message}`);
    }
  }
};

/**
 * Generate test cases for a problem
 * @param {Object} problemData - The problem data
 * @returns {Array} Generated test cases
 */
const generateTestCases = async (problemData) => {
  const maxRetries = 3;
  let attempt = 0;
  
  while (attempt < maxRetries) {
    try {
      const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });

      const prompt = `Generate ${problemData.testCaseCount || 10} diverse test cases for the following competitive programming problem:

PROBLEM:
Title: ${problemData.title}
Description: ${problemData.description}

Constraints:
${problemData.constraints.map((c, i) => `${i + 1}. ${c}`).join('\n')}

Examples:
${problemData.examples.map((ex, i) => `Example ${i + 1}:
Input: ${ex.input}
Output: ${ex.output}
Explanation: ${ex.explanation}`).join('\n\n')}

REQUIREMENTS:
Generate ${problemData.testCaseCount || 10} test cases that:
1. Cover edge cases (minimum, maximum, empty, boundary values)
2. Include normal cases with varying complexity
3. Test different problem scenarios
4. Follow the exact input/output format from examples
5. Respect all constraints
6. Ensure outputs are CORRECT based on problem logic

CRITICAL: Return response in PURE YAML format (no markdown, no code blocks).

Required structure:
---
testCases:
  - input: "test input 1"
    output: "correct output 1"
    explanation: "what this tests"
  - input: "test input 2"
    output: "correct output 2"
    explanation: "what this tests"

IMPORTANT: Start with "testCases:" - NO markdown blocks, NO extra text.`;

      console.log('=== VALIDATION PROMPT ===');
      console.log(prompt);
      console.log('=== END PROMPT ===\n');

      const result = await model.generateContent(prompt);
      const response = await result.response;
      const text = response.text();

      // Clean the response
      let cleanedText = text.trim();
      if (cleanedText.startsWith('---')) {
        cleanedText = cleanedText.substring(3).trim();
      }
      if (cleanedText.startsWith('```yaml')) {
        cleanedText = cleanedText.replace(/```yaml\n?/g, '').replace(/```\n?$/g, '');
      } else if (cleanedText.startsWith('```')) {
        cleanedText = cleanedText.replace(/```\n?/g, '').replace(/```\n?$/g, '');
      }
      cleanedText = cleanedText.replace(/```\s*$/g, '').trim();

      // Parse YAML
      const parsedData = yaml.load(cleanedText);
      
      if (!parsedData.testCases || !Array.isArray(parsedData.testCases)) {
        throw new Error('Invalid test cases format');
      }

      return parsedData.testCases;

    } catch (error) {
      attempt++;
      
      // Check if it's a rate limit error
      if (error.message && error.message.includes('quota') && attempt < maxRetries) {
        const waitTime = Math.pow(2, attempt) * 5000; // Exponential backoff: 5s, 10s, 20s
        console.log(`Rate limit hit. Waiting ${waitTime / 1000}s before retry ${attempt + 1}/${maxRetries}...`);
        await new Promise(resolve => setTimeout(resolve, waitTime));
        continue;
      }
      
      // If max retries reached or other error, throw
      if (attempt >= maxRetries) {
        console.error('Error generating test cases (max retries reached):', error);
        throw new Error(`Failed to generate test cases after ${maxRetries} attempts: ${error.message}`);
      }
      
      // For non-rate-limit errors, throw immediately
      console.error('Error generating test cases:', error);
      throw new Error(`Failed to generate test cases: ${error.message}`);
    }
  }
};

module.exports = {
  validateTestCases,
  generateTestCases
};